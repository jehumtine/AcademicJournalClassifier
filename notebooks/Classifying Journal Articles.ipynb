{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce2d96c8897dd95a",
   "metadata": {},
   "source": [
    "# Business Understanding\n",
    "## Problem Statement\n",
    "The University of Zambia (UNZA) hosts a growing repository of academic journal articles across multiple disciplines. However, these articles are not systematically categorized according to Zambia’s Vision 2030 development sectors. This lack of alignment presents a missed opportunity to leverage UNZA’s intellectual output for national strategic planning, policy formulation, and sectoral development monitoring.\n",
    "\n",
    "This project aims to develop a data-driven classification system that maps UNZA journal articles to the appropriate Vision 2030 sectors using machine learning techniques. By automating this classification, we intend to bridge the gap between academic research and national development priorities, enabling policymakers, researchers, and institutions to better identify and track sectoral contributions and trends."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cddee62",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "**1. To align the University of Zambia’s research with national priorities:**\n",
    "Systematically map academic journal articles to Zambia’s Vision 2030 development sectors to highlight how the UNZA’s intellectual output contributes to achieving national development goals.\n",
    "\n",
    "**2. To enable evidence-based decision-making:**\n",
    "Provide policymakers, researchers, and development stakeholders with an accessible, data-driven tool for identifying sectoral trends and gaps in research, thereby supporting targeted policy formulation and strategic resource allocation.\n",
    "\n",
    "**3. To automate and scale research classification:**\n",
    "Develop a machine learning–powered system to classify and update the categorization of research articles efficiently, ensuring scalability as UNZA’s repository grows and enabling continuous monitoring of sectoral contributions over time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7934fefe",
   "metadata": {},
   "source": [
    "## Data Mining Goals\n",
    "\n",
    "**1. Design a supervised multi-class classification model** to assign each UNZA journal article to one of Zambia’s Vision 2030 sectors based on the article’s metadata (title, abstract, and keywords).\n",
    "\n",
    "*Purpose*: Reveal the alignment between academic output and national development areas.\n",
    "\n",
    "*Method*: Use labeled training data mapped to Vision 2030 sectors, extracted from a subset of articles.\n",
    "\n",
    "**Expected Output**: Accurate labels such as “Education,” “Agriculture,” “Health,” “Infrastructure”, etc.\n",
    "\n",
    "**2. Identify latent research clusters and anomalies** through unsupervised learning (e.g., clustering or topic modeling) to uncover emerging themes or neglected areas.\n",
    "\n",
    "*Purpose*: Help decision-makers identify new or missing areas of national interest not currently emphasized in the Vision 2030 framework.\n",
    "\n",
    "*Method*: Apply techniques like K-Means, DBSCAN, or LDA topic modeling on text embeddings.\n",
    "\n",
    "**Expected Output**: Visual or descriptive reports of discovered themes or outliers.\n",
    "\n",
    "**3. Deploy a scalable, retrainable classification pipeline** using modern ML techniques and modular design.\n",
    "\n",
    "*Purpose*: Automate the tagging process for future UNZA research uploads.\n",
    "\n",
    "*Method*: Build a modular pipeline for preprocessing, vectorization (e.g., TF-IDF or BERT), training, evaluation, and inference.\n",
    "\n",
    "**Expected Output**: A script or web app that classifies new articles on upload.\n",
    "\n",
    "**4. Continuously evaluate model performance** over time using metrics such as F1-score, accuracy, and confusion matrices.\n",
    "\n",
    "*Purpose*: Ensure system reliability and adaptiveness as language and research topics evolve.\n",
    "\n",
    "*Method*: Establish a validation framework and regularly benchmark models.\n",
    "\n",
    "**Expected Output**: Monitoring logs or retraining criteria to prevent model drift."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa0bceb",
   "metadata": {},
   "source": [
    "## Initial Project Success Criteria\n",
    "\n",
    "The project will be considered initially successful if the supervised classification model achieves at least 60% accuracy in assigning UNZA journal articles to the correct Zambia Vision 2030 development sectors.\n",
    "\n",
    "This baseline is realistic for a first iteration, considering:\n",
    "\n",
    "Data quality issues such as incomplete or inconsistent titles, abstracts, or keywords.\n",
    "\n",
    "Sector overlap, where some research spans multiple development areas.\n",
    "\n",
    "Model maturity, as this is the initial deployment and will improve with further training and tuning.\n",
    "\n",
    "Achieving this baseline will:\n",
    "\n",
    "Demonstrate that the model performs significantly above random guessing.\n",
    "\n",
    "Provide policymakers and researchers with a usable starting point for tracking sectoral research contributions.\n",
    "\n",
    "Establish a functional foundation for refining the system toward higher accuracy and more adoption."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60384f44b96b46e",
   "metadata": {},
   "source": [
    "# Data Understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6f9ac4ea5bcc4d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-20T09:39:56.007559Z",
     "start_time": "2025-08-20T09:39:54.265090Z"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel '.venv (Python 3.13.3)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# --- Step 1: Import libraries ---\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# --- Step 2: Load dataset ---\n",
    "file_path = \"../data/vision2030_corpus.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "# --- Step 3: Initial Exploration ---\n",
    "print(\"First 5 rows:\")\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45bd0b4365cbe22",
   "metadata": {},
   "source": [
    "The code above loads the dataset into our colaborotory notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe4f7bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-20T09:40:02.696576Z",
     "start_time": "2025-08-20T09:40:02.636272Z"
    }
   },
   "outputs": [],
   "source": [
    "# --- Step 4: Summary statistics ---\n",
    "print(\"\\nInfo:\")\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc53fb2",
   "metadata": {},
   "source": [
    "Dataset has 17,136 rows × 13 columns.\n",
    "All columns are stored as object/text.\n",
    "Missing values appear mainly in authors, abstract, doi, pdf_url, and journal.\n",
    "Titles and abstracts differ in length, showing variation in metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e83388",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-20T09:40:05.711613Z",
     "start_time": "2025-08-20T09:40:05.459874Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "print(\"\\nSummary statistics (all columns):\")\n",
    "display(df.describe(include=\"all\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957d52e9",
   "metadata": {},
   "source": [
    "The code above generates descriptive statistics for both numeric and categorical columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5956a0e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-20T09:40:08.916570Z",
     "start_time": "2025-08-20T09:40:08.878979Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\nShape (rows, columns):\", df.shape)\n",
    "\n",
    "print(\"\\nMissing values per column:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2b31b1",
   "metadata": {},
   "source": [
    "The code above first prints the dataset’s overall dimensions (rows and columns) using df.shape. Then it shows how many missing values each column contains by running df.isnull().sum()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1919c921",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-20T09:40:48.279860Z",
     "start_time": "2025-08-20T09:40:47.330030Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# --- Create derived length columns ---\n",
    "df[\"title_length\"] = df[\"title\"].fillna(\"\").apply(len)\n",
    "df[\"abstract_length\"] = df[\"abstract\"].fillna(\"\").apply(len)\n",
    "\n",
    "# --- Plot histograms ---\n",
    "df[[\"title_length\", \"abstract_length\"]].hist(\n",
    "    figsize=(10, 5), bins=30, edgecolor=\"black\"\n",
    ")\n",
    "plt.suptitle(\"Distribution of Title and Abstract Lengths\", fontsize=14)\n",
    "plt.show()\n",
    "\n",
    "# Missing rate per column (in %)\n",
    "missing_rates = df.isnull().mean().sort_values(ascending=False) * 100\n",
    "\n",
    "print(\"Missing data rates (%):\")\n",
    "\n",
    "# Plot as bar chart\n",
    "plt.figure(figsize=(10,5))\n",
    "missing_rates.plot(kind=\"bar\", edgecolor=\"black\")\n",
    "plt.title(\"Missing Data Percentage by Column\", fontsize=14)\n",
    "plt.ylabel(\"Percentage (%)\")\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130ca345",
   "metadata": {},
   "source": [
    "### Dataset Summary\n",
    "\n",
    "The dataset has **17,136 rows × 13 columns** of academic publication metadata.\n",
    "\n",
    "#### Observations\n",
    "\n",
    "- **Data types**:  \n",
    "  All columns are text. `published` should be converted to `datetime` for trend analysis.  \n",
    "\n",
    "- **Missing data**:  \n",
    "  - `authors`: 81% missing  \n",
    "  - `journal`: 81% missing  \n",
    "  - `abstract`: 21% missing  \n",
    "  - `doi`: 28% missing  \n",
    "  - `pdf_url`: 56% missing  \n",
    "  - Other fields: complete  \n",
    "\n",
    "- **Uniqueness**:  \n",
    "  - `id` is unique (usable as primary key)  \n",
    "  - Titles are mostly unique (99%)  \n",
    "\n",
    "- **Distributions**:  \n",
    "  - `source` dominated by **openalex** (81%)  \n",
    "  - `assigned_sectors` has 26 categories, with **Mining** and **Agriculture** frequent  \n",
    "  - Publication years span **1994–2020+**  \n",
    "\n",
    "#### Interpretation\n",
    "\n",
    "The dataset is **large and well-structured**, but metadata gaps (authors, journals, abstracts) limit certain analyses.  \n",
    "Strong identifiers (`id`, `topics`, `assigned_sectors`) support sectoral and thematic exploration.  \n",
    "Preprocessing (handling missingness, normalizing dates) is needed for deeper analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c5fa1c4ab81797",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a9cbe173f78b26",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-20T09:51:08.075833Z",
     "start_time": "2025-08-20T09:51:07.546275Z"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel '.venv (Python 3.13.3)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e31e9798d403e0c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-20T09:55:16.731603Z",
     "start_time": "2025-08-20T09:55:16.710649Z"
    }
   },
   "outputs": [],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36266a7476e80f1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-20T09:56:32.906429Z",
     "start_time": "2025-08-20T09:56:32.800033Z"
    }
   },
   "outputs": [],
   "source": [
    "# Check the percentage of missing values for each column\n",
    "missing_percentage = (df.isnull().sum() / len(df)) * 100\n",
    "print(\"Missing Value Percentage:\\n\", missing_percentage)\n",
    "\n",
    "# For text columns, we'll fill missing values with empty strings\n",
    "text_columns = ['title', 'abstract', 'authors']\n",
    "for col in text_columns:\n",
    "    if col in df.columns:\n",
    "        df[col].fillna('', inplace=True)\n",
    "\n",
    "# For categorical columns, we'll fill with 'Unknown'\n",
    "categorical_columns = ['journal', 'topics', 'provenance_sources']\n",
    "for col in categorical_columns:\n",
    "    if col in df.columns:\n",
    "        df[col].fillna('Unknown', inplace=True)\n",
    "\n",
    "# For published date, we'll extract year and handle missing values\n",
    "df['published'] = pd.to_datetime(df['published'], errors='coerce')\n",
    "df['published_year'] = df['published'].dt.year\n",
    "df['published_year'].fillna(df['published_year'].median(), inplace=True)\n",
    "\n",
    "print(\"\\nMissing values after treatment:\\n\", df.isnull().sum())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
